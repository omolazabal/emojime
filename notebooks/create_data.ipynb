{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data\n",
    "This notebook serves the purpose of generating the training data for the EmojiMe model. The training data will consist of vectors. Each vector, representing an image, contains the combination of the distances from one facial landmark to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import dlib\n",
    "import math\n",
    "from emojime.utils import shape_to_np, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'\n",
    "emotions = ['neutral', 'happy', 'sad', 'fear', 'angry']\n",
    "\n",
    "# Set up face detector and landmarks extractor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('../models/shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract landmark distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = {}  # Contains landmark data per emotion\n",
    "for emotion in emotions:\n",
    "    img_paths = glob.glob(data_path + '/emotion-images/' + emotion + '/*.png')\n",
    "    row = 0\n",
    "    for image in  img_paths:\n",
    "        # Detect face\n",
    "        sample = cv2.imread(image)\n",
    "        rects = detector(sample, 0)\n",
    "        if len(rects) > 0:\n",
    "            # Obtain first face detected\n",
    "            rect = rects[0]\n",
    "            # Calculate landmarks\n",
    "            shape = predictor(sample, rect)\n",
    "            shape = shape_to_np(shape)\n",
    "            if row == 0:\n",
    "                landmarks[emotion] = np.zeros((1, 68*68))\n",
    "            else:\n",
    "                landmarks[emotion] = np.vstack((landmarks[emotion], np.zeros((1, 68*68))))\n",
    "            # Store landmark distances, move to next sample    \n",
    "            landmarks[emotion][row][:] = distances(shape)\n",
    "            row += 1                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create labels for feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, emotion in enumerate(emotions):\n",
    "    # Create label data\n",
    "    y = np.ones((landmarks[emotion].shape[0], 1))\n",
    "    y *= i\n",
    "    landmarks[emotion] = np.hstack((landmarks[emotion], y))\n",
    "    np.save(data_path + '/emotion-landmarks/{}_landmarks'.format(emotion), landmarks[emotion])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate data and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.copy(landmarks[emotions[0]])\n",
    "for i in range(1, len(emotions)):\n",
    "    # Stack all of the training data together\n",
    "    data = np.vstack((data, landmarks[emotions[i]]))\n",
    "np.save(data_path + '/data_set', data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
